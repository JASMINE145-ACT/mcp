"""
Chainlit Application for AI Data Analysis Agent
åŸºäº agent.py çš„å®Œæ•´ Chainlit å®ç°
"""

import chainlit as cl
import pandas as pd
import json
import os
from pathlib import Path
from typing import Optional, Dict, Any

# Import from local modules
from agent import DataAIAgent
from function import profile_dataframe_simple

# Configuration
UPLOAD_FOLDER = Path("uploads")
UPLOAD_FOLDER.mkdir(exist_ok=True)

@cl.on_chat_start
async def start():
    """åˆå§‹åŒ–èŠå¤©ä¼šè¯"""
    await cl.Message(
        content="# ğŸ¤– AI æ•°æ®åˆ†æåŠ©æ‰‹\n\n"
                "æ¬¢è¿ä½¿ç”¨æ™ºèƒ½æ•°æ®åˆ†æç³»ç»Ÿï¼\n\n"
                "**åŠŸèƒ½ç‰¹è‰²ï¼š**\n"
                "- ğŸ” æ™ºèƒ½å¯¹è¯å¼åˆ†æ\n"
                "- ğŸ“Š è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–\n"
                "- ğŸ§  å¤šæ¨¡å‹åä½œï¼ˆGPT-5-nano + Claude + Gemini + GPT-4o-miniï¼‰\n"
                "- ğŸ’¬ å¤šè½®äº¤äº’å¼è§„åˆ’\n\n"
                "**å¼€å§‹ä½¿ç”¨ï¼š**\n"
                "è¯·ä¸Šä¼  CSV æ–‡ä»¶å¼€å§‹åˆ†æ"
    ).send()
    
    # Request file upload
    files = await cl.AskFileMessage(
        content="ğŸ“ è¯·ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒ CSV æˆ– Excelï¼‰",
        accept=["text/csv", ".csv", "application/vnd.ms-excel", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", ".xlsx", ".xls"],
        max_size_mb=100,
        timeout=180,
    ).send()
    
    if files:
        file = files[0]
        await process_uploaded_file(file)

async def process_uploaded_file(file):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # Get file path (Chainlit already saves the file)
        file_path = Path(file.path)
        file_name = file.name
        
        await msg.stream_token("ğŸ“Š æ­£åœ¨åŠ è½½æ•°æ®...")
        
        # Load data based on file extension
        file_ext = file_path.suffix.lower()
        if file_ext == '.csv':
            df = pd.read_csv(file_path)
        elif file_ext in ['.xlsx', '.xls']:
            df = pd.read_excel(file_path)
        else:
            await cl.Message(
                content=f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š{file_ext}\n\nè¯·ä¸Šä¼  CSV æˆ– Excel æ–‡ä»¶ã€‚"
            ).send()
            return
        
        await msg.stream_token(f"\nâœ… æ•°æ®åŠ è½½æˆåŠŸï¼\n\n")
        await msg.stream_token(f"**æ•°æ®æ¦‚è§ˆï¼š**\n")
        await msg.stream_token(f"- æ–‡ä»¶åï¼š{file_name}\n")
        await msg.stream_token(f"- è¡Œæ•°ï¼š{len(df):,}\n")
        await msg.stream_token(f"- åˆ—æ•°ï¼š{len(df.columns)}\n")
        
        # Get file size
        file_size_bytes = file_path.stat().st_size
        file_size_mb = file_size_bytes / (1024 * 1024)
        if file_size_mb < 1:
            await msg.stream_token(f"- æ–‡ä»¶å¤§å°ï¼š{file_size_bytes / 1024:.2f} KB\n\n")
        else:
            await msg.stream_token(f"- æ–‡ä»¶å¤§å°ï¼š{file_size_mb:.2f} MB\n\n")
        
        # Profile data
        profile_data = profile_dataframe_simple(df)
        
        await msg.stream_token("**å¯ç”¨åˆ—ï¼š**\n")
        for col in profile_data.get('column_overview', [])[:10]:
            col_name = col.get('column_name', '')
            samples = col.get('sample_values', [])
            sample_str = ', '.join([str(s) for s in samples[:2]])
            await msg.stream_token(f"- `{col_name}` (ä¾‹å¦‚: {sample_str})\n")
        
        # Initialize agent
        agent = DataAIAgent(df)
        
        # Store in session
        cl.user_session.set("agent", agent)
        cl.user_session.set("profile_data", profile_data)
        cl.user_session.set("df", df)
        cl.user_session.set("file_name", file.name)
        cl.user_session.set("conversation_state", None)
        
        await msg.stream_token("\n\nâœ¨ **å‡†å¤‡å°±ç»ªï¼** æ‚¨å¯ä»¥å¼€å§‹æé—®äº†ã€‚\n\n")
        await msg.stream_token("ğŸ’¡ **ç¤ºä¾‹é—®é¢˜ï¼š**\n")
        await msg.stream_token("- è¿™ä¸ªæ•°æ®é›†æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Ÿ\n")
        await msg.stream_token("- å¸®æˆ‘åˆ†æä¸€ä¸‹ä»·æ ¼åˆ†å¸ƒ\n")
        await msg.stream_token("- ç”»ä¸€ä¸ªç®±çº¿å›¾æŒ‰ç±»åˆ«åˆ†ç»„\n")
        
        await msg.update()
        
    except Exception as e:
        await cl.Message(
            content=f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{str(e)}\n\nè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
        ).send()

@cl.on_message
async def main(message: cl.Message):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    agent = cl.user_session.get("agent")
    profile_data = cl.user_session.get("profile_data")
    conversation_state = cl.user_session.get("conversation_state")
    
    if not agent:
        await cl.Message(
            content="âš ï¸ è¯·å…ˆä¸Šä¼  CSV æ–‡ä»¶ï¼\n\nä½¿ç”¨ `/upload` å‘½ä»¤é‡æ–°ä¸Šä¼ æ–‡ä»¶ã€‚"
        ).send()
        return
    
    # Handle commands
    user_input = message.content.strip()
    
    # Check for confirm command
    if user_input.lower() in ['confirm', 'ç¡®è®¤', 'æ‰§è¡Œ']:
        await handle_confirm(agent, profile_data, conversation_state)
        return
    
    # Check for new session command
    if user_input.lower() in ['new', 'restart', 'é‡æ–°å¼€å§‹']:
        cl.user_session.set("conversation_state", None)
        await cl.Message(content="ğŸ”„ å·²é‡ç½®ä¼šè¯ï¼Œå¯ä»¥å¼€å§‹æ–°çš„åˆ†æäº†ï¼").send()
        return
    
    # Process regular question
    await process_question(agent, profile_data, conversation_state, user_input)

async def process_question(agent, profile_data, conversation_state, question):
    """å¤„ç†ç”¨æˆ·é—®é¢˜"""
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # Show thinking indicator
        await msg.stream_token("ğŸ¤” **GPT-5-nano æ­£åœ¨æ€è€ƒ...**\n\n")
        
        # Run analysis
        result = agent.langgraph_analysis(
            question=question,
            dataset_info=profile_data,
            user_feedback=None,
            existing_state=conversation_state
        )
        
        conv_state = result.get('conversation_state', {})
        
        # Check if we need user input (planning phase)
        if conv_state.get('needs_user_input', False):
            await handle_planning_response(msg, result, conv_state)
        else:
            # Execution completed
            await handle_execution_result(msg, result)
        
        await msg.update()
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        await cl.Message(
            content=f"âŒ **å‘ç”Ÿé”™è¯¯ï¼š**\n\n```\n{str(e)}\n```\n\n"
                    f"<details><summary>è¯¦ç»†ä¿¡æ¯</summary>\n\n```\n{error_detail}\n```\n</details>"
        ).send()

async def handle_planning_response(msg, result, conv_state):
    """å¤„ç†è§„åˆ’é˜¶æ®µçš„å“åº”"""
    has_concrete_plan = result.get('plan') and result.get('plan') != ""
    
    if has_concrete_plan:
        # We have a concrete plan
        await msg.stream_token("ğŸ“‹ **åˆ†æè®¡åˆ’å·²ç”Ÿæˆ**\n\n")
        
        try:
            plan_data = json.loads(result['plan'])
            analysis_plan = plan_data
            
            await msg.stream_token(f"**åˆ†æç±»å‹ï¼š** {analysis_plan.get('analysis_type', 'N/A')}\n\n")
            
            cols = analysis_plan.get('columns_needed', [])
            if cols:
                await msg.stream_token(f"**ä½¿ç”¨åˆ—ï¼š** {', '.join([f'`{c}`' for c in cols])}\n\n")
            
            method = analysis_plan.get('method', '')
            if method:
                await msg.stream_token(f"**æ–¹æ³•ï¼š**\n{method}\n\n")
            
            expected = analysis_plan.get('expected_output', '')
            if expected:
                await msg.stream_token(f"**é¢„æœŸè¾“å‡ºï¼š** {expected}\n\n")
            
        except json.JSONDecodeError:
            await msg.stream_token(f"```json\n{result.get('plan', '')}\n```\n\n")
        
        # Store state for confirmation
        cl.user_session.set("conversation_state", {
            'question': result.get('question'),
            'dataset_info': cl.user_session.get("profile_data"),
            'plan': result.get('plan', ''),
            'code': '',
            'code_validation': '',
            'code_approved': True,
            'execution_result': '',
            'validation': '',
            'final_result': {},
            'conversation_history': conv_state.get('conversation_history', []),
            'plan_iterations': conv_state.get('plan_iterations', []),
            'user_feedback': '',
            'plan_confirmed': False,
            'execution_error': False,
            'error_message': '',
            'retry_count': 0
        })
        
        # Add action buttons
        actions = [
            cl.Action(name="confirm", value="confirm", label="âœ… ç¡®è®¤æ‰§è¡Œ"),
            cl.Action(name="modify", value="modify", label="âœï¸ ä¿®æ”¹è®¡åˆ’"),
        ]
        await msg.stream_token("\n\n---\n\n")
        await msg.stream_token("ğŸ’¡ **ä¸‹ä¸€æ­¥ï¼š**\n")
        await msg.stream_token("- ç‚¹å‡» **âœ… ç¡®è®¤æ‰§è¡Œ** å¼€å§‹åˆ†æ\n")
        await msg.stream_token("- æˆ–æä¾›åé¦ˆä¿®æ”¹è®¡åˆ’\n")
        
    else:
        # Conversational mode - agent is asking for clarification
        # The message is already in conversation history
        last_msg = conv_state.get('conversation_history', [])[-1] if conv_state.get('conversation_history') else {}
        
        if last_msg and last_msg.get('role') == 'assistant':
            await msg.stream_token(f"ğŸ’¬ {last_msg.get('content', '')}\n\n")
        
        # Store minimal state
        cl.user_session.set("conversation_state", {
            'question': result.get('question'),
            'dataset_info': cl.user_session.get("profile_data"),
            'plan': '',
            'code': '',
            'code_validation': '',
            'code_approved': True,
            'execution_result': '',
            'validation': '',
            'final_result': {},
            'conversation_history': conv_state.get('conversation_history', []),
            'plan_iterations': [],
            'user_feedback': '',
            'plan_confirmed': False,
            'execution_error': False,
            'error_message': '',
            'retry_count': 0
        })
        
        await msg.stream_token("---\n\n")
        await msg.stream_token("ğŸ’¡ è¯·å›ç­”ä¸Šè¿°é—®é¢˜ä»¥ç»§ç»­...\n")

async def handle_confirm(agent, profile_data, conversation_state):
    """å¤„ç†ç¡®è®¤æ‰§è¡Œ"""
    if not conversation_state or not conversation_state.get('plan'):
        await cl.Message(
            content="âš ï¸ æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’ã€‚è¯·å…ˆæå‡ºä¸€ä¸ªå…·ä½“çš„åˆ†æé—®é¢˜ã€‚"
        ).send()
        return
    
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        await msg.stream_token("âœ… **å¼€å§‹æ‰§è¡Œåˆ†æ**\n\n")
        await msg.stream_token("---\n\n")
        
        # Mark as confirmed
        conversation_state['plan_confirmed'] = True
        conversation_state['user_feedback'] = "ç”¨æˆ·ç¡®è®¤è®¡åˆ’ï¼Œè¯·æ‰§è¡Œ"
        
        # Step 1: Code Generation
        await msg.stream_token("### ğŸ”¹ æ­¥éª¤ 1: ç”Ÿæˆä»£ç \n")
        await msg.stream_token("ğŸ’» Claude æ­£åœ¨ç”Ÿæˆä»£ç ...\n\n")
        
        result = agent.langgraph_analysis(
            question=conversation_state['question'],
            dataset_info=profile_data,
            user_feedback=conversation_state['user_feedback'],
            existing_state=conversation_state
        )
        
        if result.get('code'):
            code_preview = result['code'][:200] + "..." if len(result['code']) > 200 else result['code']
            await msg.stream_token(f"âœ… ä»£ç å·²ç”Ÿæˆ\n\n")
            await msg.stream_token(f"<details><summary>æŸ¥çœ‹ç”Ÿæˆçš„ä»£ç </summary>\n\n```python\n{result.get('code', '')}\n```\n</details>\n\n")
        
        # Step 2: Validation (if Gemini available)
        if result.get('code_validation') and result.get('code_validation') != "N/A":
            await msg.stream_token("### ğŸ”¹ æ­¥éª¤ 2: ä»£ç éªŒè¯\n")
            await msg.stream_token("ğŸ” Gemini æ­£åœ¨éªŒè¯ä»£ç é€»è¾‘...\n\n")
            
            try:
                validation_data = json.loads(result['code_validation'])
                if validation_data.get('approved'):
                    confidence = validation_data.get('confidence_score', 0)
                    await msg.stream_token(f"âœ… ä»£ç é€šè¿‡éªŒè¯ (ç½®ä¿¡åº¦: {confidence}%)\n\n")
                else:
                    await msg.stream_token(f"âš ï¸ ä»£ç å­˜åœ¨é—®é¢˜ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ...\n\n")
            except:
                await msg.stream_token(f"âœ… éªŒè¯å®Œæˆ\n\n")
        
        # Step 3: Execution
        await msg.stream_token("### ğŸ”¹ æ­¥éª¤ 3: æ‰§è¡Œåˆ†æ\n")
        await msg.stream_token("âš¡ æ­£åœ¨è¿è¡Œä»£ç ...\n\n")
        
        exec_result = result.get('execution_result', '')
        
        # Check for plots
        import re
        plot_pattern = r'Plot created successfully: ([\w\-\.]+\.png)'
        plots = re.findall(plot_pattern, exec_result)
        
        if plots:
            await msg.stream_token("âœ… åˆ†æå®Œæˆï¼\n\n")
            await msg.stream_token("**æ‰§è¡Œç»“æœï¼š**\n")
            # Remove plot messages from output
            clean_output = re.sub(plot_pattern, '', exec_result)
            await msg.stream_token(f"```\n{clean_output.strip()}\n```\n\n")
            
            # Display plots
            await msg.stream_token("**ğŸ“Š ç”Ÿæˆçš„å›¾è¡¨ï¼š**\n\n")
            for plot_file in plots:
                plot_path = Path(plot_file)
                if plot_path.exists():
                    # Send image
                    image = cl.Image(path=str(plot_path), name=plot_file, display="inline")
                    await cl.Message(
                        content=f"**{plot_file}**",
                        elements=[image]
                    ).send()
        else:
            await msg.stream_token("âœ… åˆ†æå®Œæˆï¼\n\n")
            await msg.stream_token("**æ‰§è¡Œç»“æœï¼š**\n")
            await msg.stream_token(f"```\n{exec_result}\n```\n\n")
        
        # Step 4: AI Analysis
        await msg.stream_token("### ğŸ”¹ æ­¥éª¤ 4: AI åˆ†æä¸è§£è¯»\n")
        await msg.stream_token("ğŸ§  GPT-4o-mini æ­£åœ¨åˆ†æç»“æœ...\n\n")
        
        validation = result.get('validation', '')
        try:
            val_data = json.loads(validation)
            
            if val_data.get('final_answer'):
                await msg.stream_token(f"**ğŸ“Œ ç­”æ¡ˆï¼š**\n{val_data['final_answer']}\n\n")
            
            if val_data.get('result_interpretation'):
                await msg.stream_token(f"**ğŸ’¡ è§£è¯»ï¼š**\n{val_data['result_interpretation']}\n\n")
            
            if val_data.get('recommendations'):
                await msg.stream_token(f"**ğŸ’­ å»ºè®®ï¼š**\n{val_data['recommendations']}\n\n")
        except:
            if validation:
                await msg.stream_token(f"{validation}\n\n")
        
        await msg.stream_token("---\n\n")
        await msg.stream_token("âœ¨ **åˆ†æå®Œæˆï¼** æ‚¨å¯ä»¥ç»§ç»­æå‡ºæ–°çš„é—®é¢˜ã€‚\n")
        
        # Reset conversation state
        cl.user_session.set("conversation_state", None)
        
        await msg.update()
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        await cl.Message(
            content=f"âŒ **æ‰§è¡Œå¤±è´¥ï¼š**\n\n```\n{str(e)}\n```\n\n"
                    f"<details><summary>è¯¦ç»†ä¿¡æ¯</summary>\n\n```\n{error_detail}\n```\n</details>"
        ).send()

async def handle_execution_result(msg, result):
    """å¤„ç†æ‰§è¡Œç»“æœï¼ˆè‡ªåŠ¨æ‰§è¡Œçš„æƒ…å†µï¼‰"""
    await msg.stream_token("âœ… **åˆ†æå®Œæˆï¼**\n\n")
    
    # Show execution result
    exec_result = result.get('execution_result', '')
    if exec_result:
        await msg.stream_token("**æ‰§è¡Œç»“æœï¼š**\n")
        await msg.stream_token(f"```\n{exec_result}\n```\n\n")
    
    # Show validation/analysis
    validation = result.get('validation', '')
    if validation:
        try:
            val_data = json.loads(validation)
            
            if val_data.get('final_answer'):
                await msg.stream_token(f"**ğŸ“Œ ç­”æ¡ˆï¼š** {val_data['final_answer']}\n\n")
            
            if val_data.get('result_interpretation'):
                await msg.stream_token(f"**ğŸ’¡ è§£è¯»ï¼š**\n{val_data['result_interpretation']}\n\n")
        except:
            await msg.stream_token(f"{validation}\n\n")

@cl.action_callback("confirm")
async def on_confirm_action(action: cl.Action):
    """å¤„ç†ç¡®è®¤æŒ‰é’®ç‚¹å‡»"""
    agent = cl.user_session.get("agent")
    profile_data = cl.user_session.get("profile_data")
    conversation_state = cl.user_session.get("conversation_state")
    
    await handle_confirm(agent, profile_data, conversation_state)
    
    # Remove the action buttons
    await action.remove()

@cl.action_callback("modify")
async def on_modify_action(action: cl.Action):
    """å¤„ç†ä¿®æ”¹æŒ‰é’®ç‚¹å‡»"""
    await cl.Message(
        content="ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„ä¿®æ”¹å»ºè®®..."
    ).send()
    
    await action.remove()

# Add settings
@cl.set_chat_profiles
async def chat_profile():
    return [
        cl.ChatProfile(
            name="Data Analysis",
            markdown_description="æ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹ - ä½¿ç”¨ GPT-5-nano, Claude, Gemini å’Œ GPT-4o-mini",
            icon="ğŸ“Š",
        )
    ]

